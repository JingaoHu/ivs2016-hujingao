\relax 
\citation{t_zhao}
\citation{eikvil}
\citation{p_liang}
\citation{kembhavi}
\citation{alexnet}
\citation{ilsvrc}
\citation{jiangqilin}
\citation{qushenquan}
\citation{xychen-hy}
\citation{xychen-pa}
\@writefile{toc}{\contentsline {title}{RPN-based Real-Time Vehicle Detection in Satellite Images}{1}}
\@writefile{toc}{\contentsline {author}{Jingao Hu}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{faster-rcnn}
\citation{fcn}
\citation{faster-rcnn}
\citation{fcn}
\citation{zfnet}
\citation{ilsvrc}
\@writefile{toc}{\contentsline {section}{\numberline {2}Method}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Our RPN-based detection framework. The input is a raw satellite image of 3 channels. A CNN of 5 convolution layers acts as a feature extractor. The two sibling parts, classification layer and regression layer do the following detection work. We use k anchors to hypothesize the vehicle locations}}{3}}
\newlabel{fig:example}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Architecture of RPN}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces RPN configurations. For each convolutional layer ``parameters" gives the filter size and the stride which the filter is sliding with and ``filter numbers" gives the convolution kernel numbers of that layer. The pooling layers, LRN layers and ReLU activation layers are not shown for brevity}}{3}}
\newlabel{table:headings}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Learning methodology}{3}}
\citation{fcn}
\citation{lecun89}
\citation{lecun89}
\citation{fast-rcnn}
\citation{fast-rcnn}
\citation{alexnet}
\citation{caffe}
\citation{xychen-hy}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces anchors }}{4}}
\newlabel{table:headings}{{2}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiment}{4}}
\citation{hogsvm}
\citation{lbpsvm}
\citation{adaboost}
\citation{qushenquan}
\citation{xychen-hy}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces FAR and processing time of our method and other methods on vehicle test set}}{5}}
\newlabel{table:headings}{{3}{5}}
\bibstyle{splncs}
\bibdata{egbib}
\bibcite{t_zhao}{1}
\bibcite{eikvil}{2}
\bibcite{p_liang}{3}
\bibcite{kembhavi}{4}
\bibcite{alexnet}{5}
\bibcite{ilsvrc}{6}
\bibcite{jiangqilin}{7}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Some detection results in San Francisco.The four images cover scenes from road with trees to parking lot}}{6}}
\newlabel{fig:example}{{2}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{6}}
\bibcite{qushenquan}{8}
\bibcite{xychen-hy}{9}
\bibcite{xychen-pa}{10}
\bibcite{faster-rcnn}{11}
\bibcite{fcn}{12}
\bibcite{zfnet}{13}
\bibcite{lecun89}{14}
\bibcite{fast-rcnn}{15}
\bibcite{caffe}{16}
\bibcite{hogsvm}{17}
\bibcite{lbpsvm}{18}
\bibcite{adaboost}{19}
